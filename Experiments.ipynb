{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PGU5mj_LId08"
      ],
      "authorship_tag": "ABX9TyOffWabI26hpDerf9uc3FU6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacFigNewton/SMIED/blob/main/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlZYxgBE-Z7",
        "outputId": "fbd24fbb-2922-4c91-f7be-803f7b096976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package framenet_v17 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Any, Dict, Tuple, Set\n",
        "import nltk\n",
        "nltk.download('framenet_v17')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import framenet as fn\n",
        "from nltk.corpus import wordnet as wn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get overlapping hypernym paths"
      ],
      "metadata": {
        "id": "PGU5mj_LId08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlapping_hypernym_paths(syn1, syn2) -> List[Any]:\n",
        "    lchs = syn1.lowest_common_hypernyms(syn2)\n",
        "    print(\"LCHs:\", [lch.name() for lch in lchs])\n",
        "    common_paths = []\n",
        "\n",
        "    for p1 in syn1.hypernym_paths():\n",
        "        for p2 in syn2.hypernym_paths():\n",
        "            if any(lch in p1 for lch in lchs) and any(lch in p2 for lch in lchs):\n",
        "              # truncate the paths until they've got one of the lchs\n",
        "              while p1 and p2 and p1[0] not in lchs:\n",
        "                  last_lch = p1[0]\n",
        "                  p1 = p1[1:]\n",
        "                  p2 = p2[1:]\n",
        "              # get the shared lch path\n",
        "              common_paths.append(p1[::-1] + p2[1:])\n",
        "\n",
        "    return common_paths"
      ],
      "metadata": {
        "id": "EYixUJx1HmAy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "cat = wn.synset('cat.n.01')\n",
        "dog = wn.synset('dog.n.01')\n",
        "print()\n",
        "overlaps = overlapping_hypernym_paths(cat, dog)\n",
        "for path in overlaps:\n",
        "    print(\" → \".join(s.name() for s in path))\n",
        "print()\n",
        "overlaps = overlapping_hypernym_paths(dog, cat)\n",
        "for path in overlaps:\n",
        "    print(\" → \".join(s.name() for s in path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VScLUPMTHfGz",
        "outputId": "fb07339f-5c42-462d-988e-2ce8179a0120"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LCHs: ['carnivore.n.01']\n",
            "cat.n.01 → feline.n.01 → carnivore.n.01 → canine.n.02 → dog.n.01\n",
            "\n",
            "LCHs: ['carnivore.n.01']\n",
            "dog.n.01 → canine.n.02 → carnivore.n.01 → feline.n.01 → cat.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get frame info from predicate token"
      ],
      "metadata": {
        "id": "mFoGKsvjvcBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Token, Doc\n",
        "from spacy import displacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "hr31dbWvvf31"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a dict of all dependency schemas matching a synset's frames/usage"
      ],
      "metadata": {
        "id": "VtA_LjJE0R-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Token\n",
        "\n",
        "# Register a custom extension for original POS if you want to store it\n",
        "if not Token.has_extension(\"orig_tag\"):\n",
        "    Token.set_extension(\"orig_tag\", default=None)\n",
        "\n",
        "@spacy.language.Language.component(\"custom_pos_modifier\")\n",
        "def custom_pos_modifier(doc):\n",
        "    mapping = {\"something\": \"NN\", \"someone\": \"NN\"}  # Use suitable tag string\n",
        "    for token in doc:\n",
        "        # Save original tag\n",
        "        token._.orig_tag = token.tag_\n",
        "\n",
        "        if token.text.lower() not in mapping and token.pos_ == \"NOUN\":\n",
        "            token.tag_ = \"VB\"  # Set fine-grained tag to verb\n",
        "        # Else, you could override mapping if needed\n",
        "\n",
        "    return doc\n",
        "\n",
        "arg_schema_nlp = spacy.load(\"en_core_web_sm\")\n",
        "arg_schema_nlp.add_pipe(\"custom_pos_modifier\", after=\"tagger\")\n",
        "print(arg_schema_nlp.pipe_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc9WPYWq_Dvx",
        "outputId": "aa59e16e-d72f-4878-e329-0df42d916840"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'tagger', 'custom_pos_modifier', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _flatten_tok_deps(tok: Token) -> Set[Token]:\n",
        "    deps = set()\n",
        "    for child in tok.children:\n",
        "        deps.add(child)\n",
        "        deps.update(_flatten_tok_deps(child))\n",
        "    return deps\n",
        "\n",
        "# TODO: retain original arg structure and add other syntactic/lexical info for better SRL\n",
        "def _flattened_fn_arg_schema(doc: Doc|Token) -> Dict[str, str]:\n",
        "      # used as fallback if FE parsing fails later on\n",
        "      schema_atom_synset_maps = {\n",
        "          \"something\": \"entity.n.01\",\n",
        "          \"someone\": \"causal_agent.n.01\",\n",
        "      }\n",
        "\n",
        "      # if it's a token, just flatten its children and call that set a doc\n",
        "      if isinstance(doc, Token):\n",
        "          doc: Set[Token] = _flatten_tok_deps(doc)\n",
        "\n",
        "      arg_schema = dict()\n",
        "      for tok in doc:\n",
        "          if tok.lower in schema_atom_synset_maps.keys():\n",
        "              arg_schema[tok.dep_] = schema_atom_synset_maps[tok.lower]\n",
        "          else:\n",
        "              arg_schema[tok.dep_] = tok.lemma_\n",
        "      return arg_schema"
      ],
      "metadata": {
        "id": "1p1LEnCu1arx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect_order = [\"subject\", \"object\"]  #, \"theme\"]\n",
        "arg_schema_dep_req_map = {\n",
        "    \"subject\": {\"nsubj\", \"nsubjpass\"},\n",
        "    \"object\": {\"dobj\", \"dative\"},\n",
        "    # \"theme\": {\"iobj\", \"pobj\"}\n",
        "}"
      ],
      "metadata": {
        "id": "qxwJ3--fLsgI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_dep_reqs(doc: Doc|Token) -> Tuple[bool, bool]:\n",
        "      arg_schema_reqs = _flattened_fn_arg_schema(doc)\n",
        "\n",
        "      # restructure arg_reqs based to only evaluate core dependencies\n",
        "      #   TODO: add more relationships for finer-grained SRL\n",
        "      return tuple([\n",
        "          len(arg_schema_dep_req_map[k].intersection(set(arg_schema_reqs.keys()))) > 0\n",
        "          for k in vect_order\n",
        "      ])"
      ],
      "metadata": {
        "id": "zefKVmTqH3GV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_f_id_arg_struct_dict(syn: wn.synset) -> Dict[int, Dict[str, bool]]:\n",
        "      syn_frame_ids_strs: Dict[int, Doc] = dict()\n",
        "      for lemma in syn.lemmas():\n",
        "\n",
        "          # get all FrameNet frame IDs for this lemma\n",
        "          for i, f_id in enumerate(lemma.frame_ids()):\n",
        "\n",
        "              # get the argument structure for this frame as a string\n",
        "              f_str = lemma.frame_strings()[i]\n",
        "              # parse f_str into an argument structure vector\n",
        "              #   use tuple to make it hashable\n",
        "              f_arg_structure = f_str.split(' ')\n",
        "\n",
        "              # remove any extra arguments beyond subject, object, theme\n",
        "              if f_arg_structure[-1] != f_arg_structure[-1].lower():\n",
        "                  f_arg_structure = f_arg_structure[:-1]\n",
        "\n",
        "              # create a spacy doc for the argument structure template\n",
        "              doc = arg_schema_nlp(' '.join(f_arg_structure))\n",
        "              # # display dependency parse tree for debugging\n",
        "              # displacy.render(doc, style='dep')\n",
        "\n",
        "              syn_frame_ids_strs[f_id] = _get_dep_reqs(doc)\n",
        "\n",
        "      return syn_frame_ids_strs"
      ],
      "metadata": {
        "id": "4Xtwh7hLy6aM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_id_docs = _get_f_id_arg_struct_dict(wn.synset('spin.v.01'))"
      ],
      "metadata": {
        "id": "VkCbL9cbzh64"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Wordnet frames structures that match the structure of the dependency parse of the original predicate token"
      ],
      "metadata": {
        "id": "HCElGXuM0bCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_candidate_wn_frames(pred_tok: spacy.tokens.Token) -> Dict[str, Set[Tuple[bool, bool]]]:\n",
        "      # since wordnet frames only support a max of 2 args, even for ditransitive verbs,\n",
        "      #   truncate to just subj, obj roles\n",
        "      original_tok_dep_reqs = _get_dep_reqs(pred_tok)\n",
        "      print(f\"Original pred_tok dependency structure requirements: {original_tok_dep_reqs}\")\n",
        "\n",
        "      # get candidate WordNet synsets for the predicate (verbs)\n",
        "      pred_lemma = pred_tok.lemma_.lower()\n",
        "      # get a dict of synset names and synset objects for quick lookup\n",
        "      pred_synsets = wn.synsets(pred_lemma, pos=wn.VERB)\n",
        "      pred_synsets = {syn.name(): syn for syn in pred_synsets}\n",
        "      # create a dict of synset names and lists of their possible frames,\n",
        "      #   indexed by argument structure (num args of each type)\n",
        "      pred_frames: Dict[str, Set[Tuple[bool, bool]]] = dict()\n",
        "\n",
        "      # get all FrameNet frames associated with this synset\n",
        "      for s_name, syn in pred_synsets.items():\n",
        "          for frame_id, arg_struct_tuple in _get_f_id_arg_struct_dict(syn).items():\n",
        "              # ensure the proposed tuple matches the requirements of the original token\n",
        "              if arg_struct_tuple == original_tok_dep_reqs:\n",
        "                  if s_name not in pred_frames:\n",
        "                      pred_frames[s_name] = set()\n",
        "                  # add wordnet's frame requirements as an entry in the synset's nested dict\n",
        "                  pred_frames[s_name].add(arg_struct_tuple)\n",
        "\n",
        "      return pred_frames"
      ],
      "metadata": {
        "id": "pU-sJtLzxPpo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "test_doc = nlp(\"I struck the cobra with my axe.\")\n",
        "displacy.render(test_doc, style='dep')\n",
        "pprint.pprint(_get_candidate_wn_frames(test_doc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "5Fh-ElkL5NSk",
        "outputId": "a6d5a761-8fbe-4ac8-d63b-4dd7f23b3b74"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"178c5dc5cea84f2fa1cf64717664d136-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">struck</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">cobra</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">my</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">axe.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-178c5dc5cea84f2fa1cf64717664d136-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-178c5dc5cea84f2fa1cf64717664d136-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original pred_tok dependency structure requirements: (True, True)\n",
            "{'assume.v.05': {(True, True)},\n",
            " 'come_to.v.03': {(True, True)},\n",
            " 'fall_upon.v.01': {(True, True)},\n",
            " 'hit.v.12': {(True, True)},\n",
            " 'mint.v.01': {(True, True)},\n",
            " 'strickle.v.02': {(True, True)},\n",
            " 'strike.v.01': {(True, True)},\n",
            " 'strike.v.04': {(True, True)},\n",
            " 'strike.v.10': {(True, True)},\n",
            " 'strike.v.13': {(True, True)},\n",
            " 'strike.v.14': {(True, True)},\n",
            " 'strike.v.21': {(True, True)}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "We267itBKn2Z"
      },
      "execution_count": 62,
      "outputs": []
    }
  ]
}