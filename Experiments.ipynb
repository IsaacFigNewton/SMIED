{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PGU5mj_LId08",
        "HCElGXuM0bCJ"
      ],
      "authorship_tag": "ABX9TyO2BTsV8gLOWy4ZVXqdBIZX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsaacFigNewton/SMIED/blob/main/Experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and config"
      ],
      "metadata": {
        "id": "KBBDApWoeCxZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPlZYxgBE-Z7",
        "outputId": "812aea64-c9b1-4fbd-c16b-c9db5a359386"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package framenet_v17 to /root/nltk_data...\n",
            "[nltk_data]   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from typing import List, Any, Dict, Tuple, Set\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('framenet_v17')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import framenet as fn\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Token, Doc\n",
        "from spacy import displacy\n",
        "\n",
        "max_samples = 2\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test different wn, fn library functionality"
      ],
      "metadata": {
        "id": "KBZNi8xldiBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets(\"running\")[:max_samples]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO0tup_gxxuF",
        "outputId": "98200a02-45d5-4a12-fbb0-c3df64b7332c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('run.n.05'), Synset('run.n.07')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = 'n'\n",
        "cache = defaultdict(list)\n",
        "for frame in fn.frames()[:max_samples]:\n",
        "    print(frame.name)\n",
        "    for i, (lu_name, lu_data) in enumerate(frame.lexUnit.items()):\n",
        "      if i >= max_samples:\n",
        "        break\n",
        "      print(f\"\\t{lu_name}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBU_wkh_dn8t",
        "outputId": "279e0f14-5014-457a-cb9c-8e85e4e95eac"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abandonment\n",
            "\tabandon.v\n",
            "\tleave.v\n",
            "\n",
            "Abounding_with\n",
            "\tteem.v\n",
            "\tcrawling.a\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get overlapping hypernym paths"
      ],
      "metadata": {
        "id": "PGU5mj_LId08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def overlapping_hypernym_paths(syn1, syn2) -> List[Any]:\n",
        "    lchs = syn1.lowest_common_hypernyms(syn2)\n",
        "    print(\"LCHs:\", [lch.name() for lch in lchs])\n",
        "    common_paths = []\n",
        "\n",
        "    for p1 in syn1.hypernym_paths():\n",
        "        for p2 in syn2.hypernym_paths():\n",
        "            if any(lch in p1 for lch in lchs) and any(lch in p2 for lch in lchs):\n",
        "              # truncate the paths until they've got one of the lchs\n",
        "              while p1 and p2 and p1[0] not in lchs:\n",
        "                  last_lch = p1[0]\n",
        "                  p1 = p1[1:]\n",
        "                  p2 = p2[1:]\n",
        "              # get the shared lch path\n",
        "              common_paths.append(p1[::-1] + p2[1:])\n",
        "\n",
        "    return common_paths"
      ],
      "metadata": {
        "id": "EYixUJx1HmAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example:\n",
        "cat = wn.synset('cat.n.01')\n",
        "dog = wn.synset('dog.n.01')\n",
        "print()\n",
        "overlaps = overlapping_hypernym_paths(cat, dog)\n",
        "for path in overlaps:\n",
        "    print(\" → \".join(s.name() for s in path))\n",
        "print()\n",
        "overlaps = overlapping_hypernym_paths(dog, cat)\n",
        "for path in overlaps:\n",
        "    print(\" → \".join(s.name() for s in path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VScLUPMTHfGz",
        "outputId": "fb07339f-5c42-462d-988e-2ce8179a0120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LCHs: ['carnivore.n.01']\n",
            "cat.n.01 → feline.n.01 → carnivore.n.01 → canine.n.02 → dog.n.01\n",
            "\n",
            "LCHs: ['carnivore.n.01']\n",
            "dog.n.01 → canine.n.02 → carnivore.n.01 → feline.n.01 → cat.n.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get frame info from predicate token"
      ],
      "metadata": {
        "id": "mFoGKsvjvcBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a dict of all dependency schemas matching a synset's frames/usage"
      ],
      "metadata": {
        "id": "VtA_LjJE0R-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Token\n",
        "\n",
        "# Register a custom extension for original POS if you want to store it\n",
        "if not Token.has_extension(\"orig_tag\"):\n",
        "    Token.set_extension(\"orig_tag\", default=None)\n",
        "\n",
        "@spacy.language.Language.component(\"custom_pos_modifier\")\n",
        "def custom_pos_modifier(doc):\n",
        "    mapping = {\"something\": \"NN\", \"someone\": \"NN\"}  # Use suitable tag string\n",
        "    for token in doc:\n",
        "        # Save original tag\n",
        "        token._.orig_tag = token.tag_\n",
        "\n",
        "        if token.text.lower() not in mapping and token.pos_ == \"NOUN\":\n",
        "            token.tag_ = \"VB\"  # Set fine-grained tag to verb\n",
        "        # Else, you could override mapping if needed\n",
        "\n",
        "    return doc\n",
        "\n",
        "arg_schema_nlp = spacy.load(\"en_core_web_sm\")\n",
        "arg_schema_nlp.add_pipe(\"custom_pos_modifier\", after=\"tagger\")\n",
        "print(arg_schema_nlp.pipe_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc9WPYWq_Dvx",
        "outputId": "61c13237-b999-4781-fdbe-57be6f3ae5a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'tagger', 'custom_pos_modifier', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _flatten_tok_deps(tok: Token) -> Set[Token]:\n",
        "    deps = set()\n",
        "    for child in tok.children:\n",
        "        deps.add(child)\n",
        "        deps.update(_flatten_tok_deps(child))\n",
        "    return deps\n",
        "\n",
        "# TODO: retain original arg structure and add other syntactic/lexical info for better SRL\n",
        "def _flattened_fn_arg_schema(doc: Doc|Token) -> Dict[str, str]:\n",
        "      # used as fallback if FE parsing fails later on\n",
        "      schema_atom_synset_maps = {\n",
        "          \"something\": \"entity.n.01\",\n",
        "          \"someone\": \"causal_agent.n.01\",\n",
        "      }\n",
        "\n",
        "      # if it's a token, just flatten its children and call that set a doc\n",
        "      if isinstance(doc, Token):\n",
        "          doc: Set[Token] = _flatten_tok_deps(doc)\n",
        "\n",
        "      arg_schema = dict()\n",
        "      for tok in doc:\n",
        "          if tok.lower in schema_atom_synset_maps.keys():\n",
        "              arg_schema[tok.dep_] = schema_atom_synset_maps[tok.lower]\n",
        "          else:\n",
        "              arg_schema[tok.dep_] = tok.lemma_\n",
        "      return arg_schema"
      ],
      "metadata": {
        "id": "1p1LEnCu1arx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect_order = [\"subject\", \"object\"]  #, \"theme\"]\n",
        "arg_schema_dep_req_map = {\n",
        "    \"subject\": {\"nsubj\", \"nsubjpass\"},\n",
        "    \"object\": {\"dobj\", \"obj\", \"pobj\"},\n",
        "    \"theme\": {\"iobj\"}\n",
        "}"
      ],
      "metadata": {
        "id": "qxwJ3--fLsgI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_arg_schema_doc(lemma):\n",
        "      # get the argument structure for this frame as a string\n",
        "      f_str = lemma.frame_strings()[i]\n",
        "      # parse f_str into an argument structure vector\n",
        "      #   use tuple to make it hashable\n",
        "      f_arg_structure = f_str.split(' ')\n",
        "\n",
        "      # remove any extra arguments beyond subject, object, theme\n",
        "      if f_arg_structure[-1] != f_arg_structure[-1].lower():\n",
        "          f_arg_structure = f_arg_structure[:-1]\n",
        "\n",
        "      # create a spacy doc for the argument structure template\n",
        "      doc = arg_schema_nlp(' '.join(f_arg_structure))\n",
        "      # # display dependency parse tree for debugging\n",
        "      # displacy.render(doc, style='dep')\n",
        "      return doc"
      ],
      "metadata": {
        "id": "m3mBfDe-goLO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_dep_reqs(doc: Doc|Token) -> Tuple[bool, bool]:\n",
        "      arg_schema_reqs = _flattened_fn_arg_schema(doc)\n",
        "\n",
        "      # restructure arg_reqs based to only evaluate core dependencies\n",
        "      #   TODO: add more relationships for finer-grained SRL\n",
        "      return tuple([\n",
        "          len(arg_schema_dep_req_map[k].intersection(set(arg_schema_reqs.keys()))) > 0\n",
        "          for k in vect_order\n",
        "      ])"
      ],
      "metadata": {
        "id": "zefKVmTqH3GV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _get_f_id_arg_struct_dict(syn: wn.synset) -> Dict[int, Dict[str, bool]]:\n",
        "      syn_frame_ids_strs: Dict[int, Doc] = dict()\n",
        "      for lemma in syn.lemmas():\n",
        "\n",
        "          # get all FrameNet frame IDs for this lemma\n",
        "          for i, f_id in enumerate(lemma.frame_ids()):\n",
        "              doc = _get_arg_schema_doc(lemma)\n",
        "\n",
        "              syn_frame_ids_strs[f_id] = _get_dep_reqs(doc)\n",
        "\n",
        "      return syn_frame_ids_strs"
      ],
      "metadata": {
        "id": "4Xtwh7hLy6aM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_id_docs = _get_f_id_arg_struct_dict(wn.synset('spin.v.01'))"
      ],
      "metadata": {
        "id": "VkCbL9cbzh64"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Wordnet frames structures that match the structure of the dependency parse of the original predicate token"
      ],
      "metadata": {
        "id": "HCElGXuM0bCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _apply_frame_based_WSD_filter(pred_tok: spacy.tokens.Token) -> Tuple[Set[str], Tuple[bool, bool]]:\n",
        "      # since wordnet frames only support a max of 2 args, even for ditransitive verbs,\n",
        "      #   truncate to just subj, obj roles\n",
        "      original_tok_dep_reqs = _get_dep_reqs(pred_tok)\n",
        "      print(f\"Original pred_tok dependency structure requirements: {original_tok_dep_reqs}\")\n",
        "\n",
        "      # get candidate WordNet synsets for the predicate (verbs)\n",
        "      pred_lemma = pred_tok.lemma_.lower()\n",
        "      # get a dict of synset names and synset objects for quick lookup\n",
        "      pred_synsets = wn.synsets(pred_lemma, pos=wn.VERB)\n",
        "      pred_synsets = {syn.name(): syn for syn in pred_synsets}\n",
        "\n",
        "      # filter pred_synsets by their wordnet frames\n",
        "      filtered_synsets: Set[str] = set()\n",
        "      for s_name, syn in pred_synsets.items():\n",
        "          for frame_id, arg_struct_tuple in _get_f_id_arg_struct_dict(syn).items():\n",
        "              # ensure the proposed tuple matches the requirements of the original token\n",
        "              if arg_struct_tuple == original_tok_dep_reqs:\n",
        "                  filtered_synsets.add(s_name)\n",
        "\n",
        "      return filtered_synsets, original_tok_dep_reqs"
      ],
      "metadata": {
        "id": "pU-sJtLzxPpo"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "test_doc = nlp(\"I struck the cobra with my axe.\")\n",
        "displacy.render(test_doc, style='dep')\n",
        "pprint.pprint(_apply_frame_based_WSD_filter(test_doc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "5Fh-ElkL5NSk",
        "outputId": "f3015280-194b-4389-e9ff-2f3f52e9da12"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"39ba864cefe54c89beaca7b948c88fda-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">struck</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">cobra</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">my</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">axe.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-2\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-39ba864cefe54c89beaca7b948c88fda-0-5\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-39ba864cefe54c89beaca7b948c88fda-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original pred_tok dependency structure requirements: (True, True)\n",
            "({'assume.v.05',\n",
            "  'come_to.v.03',\n",
            "  'fall_upon.v.01',\n",
            "  'hit.v.12',\n",
            "  'mint.v.01',\n",
            "  'strickle.v.02',\n",
            "  'strike.v.01',\n",
            "  'strike.v.04',\n",
            "  'strike.v.10',\n",
            "  'strike.v.13',\n",
            "  'strike.v.14',\n",
            "  'strike.v.21'},\n",
            " (True, True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test more wn, fn functionality"
      ],
      "metadata": {
        "id": "bIwksefAhDFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # nouns don't have frames in wordnet\n",
        "# syn = wn.synset('cat.n.01')\n",
        "# for lemma in syn.lemmas():\n",
        "#       doc = _get_arg_schema_doc(lemma)\n",
        "#       displacy.render(doc, style='dep')"
      ],
      "metadata": {
        "id": "We267itBKn2Z"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try getting framenet frame for wordnet sense using Universal Verb Index (UVI)"
      ],
      "metadata": {
        "id": "npyTmzRrhXi3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pyYKyI5_hIoa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}